{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import yaml\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.feature_extraction import feature_extraction\n",
    "from src.utils import get_root_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get root directory of the project\n",
    "root_dir = get_root_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximize Column Display \n",
    "pd.set_option('display.max_colwidth', None)     # Display all content within each cell without truncation\n",
    "pd.set_option('display.max_columns', None)      # Display all columns\n",
    "pd.set_option('display.width', None)            # Display entire width of DataFrame is displayed\n",
    "\n",
    "pd.set_option('display.max_rows', None)         # Display all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Traffic Signal Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDOT D5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "signal_ids = [\n",
    "    \"1285\", \"1290\",\n",
    "    \"1300\", \"1315\", \"1325\", \"1330\", \n",
    "    \"1455\", \"1470\", \"1490\",\n",
    "    \"1500\", \"1555\",\n",
    "    \"1707\", \"1725\", \"1790\", \"1795\", \n",
    "    \"1960\",\n",
    "    \"2055\", \n",
    "    \"2485\", \n",
    "    \"2665\", \n",
    "    # \"D5I-3000\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_ids = [\"1500\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for signal_id in signal_ids:\n",
    "#     print(f\"Processing Signal ID: {signal_id}\")\n",
    "#     print(\"=\" * 40)\n",
    "\n",
    "#     # Define the filepaths\n",
    "#     filepaths = f\"../data/interim/atspm/fdot_d5/event_data/{signal_id}/*.pkl\"\n",
    "#     filepaths = [p for p in glob.glob(filepaths)][1:]  # Exclude first file, if needed\n",
    "\n",
    "#     # Extract dates from filepaths\n",
    "#     dates = [os.path.basename(filepath).split(\".\")[0] for filepath in filepaths]\n",
    "\n",
    "#     for date in dates:\n",
    "#         print(f\"  Processing Date: {date}\")\n",
    "\n",
    "#         try:\n",
    "#             # Parse the date string into a datetime object\n",
    "#             date_object = datetime.strptime(date, '%Y-%m-%d')\n",
    "\n",
    "#             # Extract day, month, and year\n",
    "#             day = date_object.day\n",
    "#             month = date_object.month\n",
    "#             year = date_object.year\n",
    "\n",
    "#             # if not ((month == 6) and (day in [1, 2])):\n",
    "#             #     continue\n",
    "\n",
    "#             if month != 6:\n",
    "#                 continue\n",
    "\n",
    "#             # Extract Traffic Signal Profile\n",
    "#             # traffic_signal_profile = feature_extraction.TrafficSignalProfile(day=day, \n",
    "#             #                                                                  month=month, \n",
    "#             #                                                                  year=year)\n",
    "\n",
    "#             # df_vehicle_phase_profile_id = traffic_signal_profile.extract_vehicle_phase_profile(signal_id=signal_id)\n",
    "#             # df_vehicle_cycle_profile_id = traffic_signal_profile.extract_vehicle_cycle_profile(signal_id=signal_id)\n",
    "\n",
    "#             # df_pedestrian_phase_profile_id = traffic_signal_profile.extract_pedestrian_phase_profile(signal_id=signal_id)\n",
    "#             # df_pedestrian_cycle_profile_id = traffic_signal_profile.extract_pedestrian_cycle_profile(signal_id=signal_id)\n",
    "\n",
    "#             # # Extract signal features\n",
    "#             # signal_feature_extract = feature_extraction.SignalFeatureExtract(day=day, \n",
    "#             #                                                                  month=month, \n",
    "#             #                                                                  year=year)\n",
    "\n",
    "#             # print(\"   # Extracting SPaT\")\n",
    "#             # df_spat_id = signal_feature_extract.extract_spat(signal_id=signal_id)\n",
    "\n",
    "#             # Extract traffic features\n",
    "#             traffic_feature_extract = feature_extraction.TrafficFeatureExtract(day=day, \n",
    "#                                                                                month=month,\n",
    "#                                                                                year=year)\n",
    "#             # # Volume\n",
    "#             # print(\"   # Extracting Volume\")\n",
    "#             # df_volume_id = traffic_feature_extract.extract_volume(signal_id=signal_id, \n",
    "#             #                                                       with_countbar=False)\n",
    "            \n",
    "#             # # Occupancy\n",
    "#             # print(\"   # Extracting Occupancy\")\n",
    "#             # df_occupancy_id = traffic_feature_extract.extract_occupancy(signal_id=signal_id)\n",
    "\n",
    "#             # # Split Failure\n",
    "#             # print(\"   # Extracting Split Failure\")\n",
    "#             # df_split_failure_id = traffic_feature_extract.extract_split_failure(signal_id=signal_id, \n",
    "#             #                                                                     purdue_standard=True)\n",
    "\n",
    "#             # # Headway\n",
    "#             # print(\"   # Extracting Headway\")\n",
    "#             # df_headway_id = traffic_feature_extract.extract_headway(signal_id=signal_id)\n",
    "\n",
    "#             # # Conflict\n",
    "#             # print(\"   # Extracting Conflict\")\n",
    "#             # df_conflict_id = traffic_feature_extract.extract_conflict(signal_id=signal_id)\n",
    "\n",
    "#             # # Gap\n",
    "#             # print(\"   # Extracting Gap\")\n",
    "#             # df_gap_id = traffic_feature_extract.extract_gap(signal_id=signal_id)\n",
    "            \n",
    "#             # # Red Light Running\n",
    "#             # print(\"   # Extracting Red Light Running\")\n",
    "#             # df_red_running_id = traffic_feature_extract.extract_red_running(signal_id=signal_id, \n",
    "#             #                                                                 with_countbar=False)\n",
    "\n",
    "#             # # Pedestrian Activity\n",
    "#             # print(\"   # Extracting Pedestrian Activity\")\n",
    "#             # df_pedestrian_activity_id = traffic_feature_extract.extract_pedestrian_activity(signal_id=signal_id)\n",
    "\n",
    "#             # # Pedestrian Delay\n",
    "#             # print(\"   # Extracting Pedestrian Delay\")\n",
    "#             # df_pedestrian_delay_id = traffic_feature_extract.extract_pedestrian_delay(signal_id=signal_id)\n",
    "\n",
    "#             # # Vehicle-Pedestrian Conflict Intensity\n",
    "#             # print(\"   # Extracting Vehicle-Pedestrian Conflict Intensity\")\n",
    "#             # df_turn_conflict_intensity_id = traffic_feature_extract.extract_turn_conflict_intensity(signal_id=signal_id)\n",
    "\n",
    "#             print(\"\\n\")\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error Processing Date {date}: {e}\")\n",
    "\n",
    "#     # Explicitly call garbage collector\n",
    "#     gc.collect()\n",
    "\n",
    "#     # Clear output after processing each Signal ID\n",
    "#     clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the directory paths\n",
    "# dirpaths = \"../data/production/atspm/fdot_d5/feature_extraction/feature/*\"\n",
    "# dirpaths = [dirpath for dirpath in glob.glob(dirpaths)]\n",
    "\n",
    "# # Initialize dictionary to hold DataFrames\n",
    "# dict_join = {f\"df_{os.path.basename(dirpath)}\": pd.DataFrame() for dirpath in dirpaths}\n",
    "\n",
    "# # Iterate through each directory path\n",
    "# for dirpath in tqdm.tqdm(dirpaths):\n",
    "#     print(dirpath)\n",
    "#     key = os.path.basename(dirpath)  # Extract the last part of the path for the key\n",
    "#     event_types = [\"vehicle_signal\", \"vehicle_traffic\", \"pedestrian_traffic\"]\n",
    "\n",
    "#     for event_type in event_types:\n",
    "#         event_path = f\"{dirpath}/{event_type}\"\n",
    "\n",
    "#         # Check if the event path exists to avoid errors\n",
    "#         if not os.path.exists(event_path):\n",
    "#             continue\n",
    "\n",
    "#         features = os.listdir(event_path)\n",
    "\n",
    "#         for feature in features:\n",
    "#             if feature != \"gap\":\n",
    "#                 continue\n",
    "#             feature_path = f\"{event_path}/{feature}\"\n",
    "\n",
    "#             signal_ids = os.listdir(feature_path)\n",
    "\n",
    "#             df = pd.DataFrame()\n",
    "#             for signal_id in signal_ids:\n",
    "#                 signal_path = f\"{feature_path}/{signal_id}\"\n",
    "#                 filepaths = glob.glob(f\"{signal_path}/*\")\n",
    "\n",
    "#                 # Read and concatenate all files for the current signal ID\n",
    "#                 for filepath in filepaths:\n",
    "#                     df = pd.concat([df, pd.read_pickle(filepath)], axis=0, ignore_index=True)\n",
    "\n",
    "#             # Merge or concatenate with the corresponding DataFrame in dict_join\n",
    "#             common_columns = list(set(df.columns).intersection(set(dict_join[f\"df_{key}\"].columns)))\n",
    "\n",
    "#             if not common_columns:\n",
    "#                 # If no common columns, concatenate along axis=1\n",
    "#                 dict_join[f\"df_{key}\"] = pd.concat([dict_join[f\"df_{key}\"], df], axis=1)\n",
    "#             else:\n",
    "#                 common_columns = [\n",
    "#                     common_column for common_column in common_columns if \"channelNos\" not in common_column\n",
    "#                 ]\n",
    "                \n",
    "#                 # If common columns exist, perform a left merge\n",
    "#                 dict_join[f\"df_{key}\"] = pd.merge(dict_join[f\"df_{key}\"], df, on=common_columns, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in [\"cycle\", \"hourly\"]:\n",
    "#     columns = [column for column in dict_join[f\"df_{key}\"].columns if \"_\" not in column]\n",
    "#     dict_join[f\"df_{key}\"] = dict_join[f\"df_{key}\"][columns]\n",
    "\n",
    "#     dict_join[f\"df_{key}\"].to_csv(f\"../data/production/atspm/fdot_d5/feature_extraction/feature/{key}/{key}.csv\", \n",
    "#                                   index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDOT D7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configurations\n",
    "# signal_ids = [\n",
    "#     \"1067\", \"1068\", \"1301\", \"1392\", \"1435\", \"1439\", \"1445\", \"1501\", \"1506\"\n",
    "#  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for signal_id in signal_ids:\n",
    "#     print(f\"Processing Signal ID: {signal_id}\")\n",
    "#     print(\"=\" * 40)\n",
    "\n",
    "#     # Define the filepaths\n",
    "#     filepaths = f\"../data/interim/atspm/fdot_d7/event_data/{signal_id}/*.pkl\"\n",
    "#     filepaths = [p for p in glob.glob(filepaths)][1:]  # Exclude first file, if needed\n",
    "\n",
    "#     # Extract dates from filepaths\n",
    "#     dates = [os.path.basename(filepath).split(\".\")[0] for filepath in filepaths]\n",
    "\n",
    "#     for date in dates:\n",
    "#         print(f\"  Processing Date: {date}\")\n",
    "\n",
    "#         try:\n",
    "#             # Parse the date string into a datetime object\n",
    "#             date_object = datetime.strptime(date, '%Y-%m-%d')\n",
    "\n",
    "#             # Extract day, month, and year\n",
    "#             day = date_object.day\n",
    "#             month = date_object.month\n",
    "#             year = date_object.year\n",
    "\n",
    "#             # Extract Traffic Signal Profile\n",
    "#             traffic_signal_profile = feature_extraction.TrafficSignalProfile(day=day, \n",
    "#                                                                              month=month, \n",
    "#                                                                              year=year)\n",
    "#             df_vehicle_phase_profile_id = traffic_signal_profile.extract_vehicle_phase_profile(signal_id=signal_id)\n",
    "#             df_vehicle_cycle_profile_id = traffic_signal_profile.extract_vehicle_cycle_profile(signal_id=signal_id)\n",
    "\n",
    "#             df_pedestrian_phase_profile_id = traffic_signal_profile.extract_pedestrian_phase_profile(signal_id=signal_id)\n",
    "#             df_pedestrian_cycle_profile_id = traffic_signal_profile.extract_pedestrian_cycle_profile(signal_id=signal_id)\n",
    "\n",
    "#             # Extract signal features\n",
    "#             signal_feature_extract = feature_extraction.SignalFeatureExtract(day=day, \n",
    "#                                                                              month=month, \n",
    "#                                                                              year=year)\n",
    "\n",
    "#             print(\"   # Extracting SPaT\")\n",
    "#             df_spat_id = signal_feature_extract.extract_spat(signal_id=signal_id)\n",
    "\n",
    "#             # Extract traffic features\n",
    "#             traffic_feature_extract = feature_extraction.TrafficFeatureExtract(day=day, \n",
    "#                                                                                month=month,\n",
    "#                                                                                year=year)\n",
    "#             # Volume\n",
    "#             print(\"   # Extracting Volume\")\n",
    "#             df_volume_id = traffic_feature_extract.extract_volume(signal_id=signal_id, \n",
    "#                                                                   with_countbar=True)\n",
    "            \n",
    "#             # Occupancy\n",
    "#             print(\"   # Extracting Occupancy\")\n",
    "#             df_occupancy_id = traffic_feature_extract.extract_occupancy(signal_id=signal_id)\n",
    "\n",
    "#             # # Split Failure\n",
    "#             # print(\"   # Extracting Split Failure\")\n",
    "#             # df_split_failure_id = traffic_feature_extract.extract_split_failure(signal_id=signal_id)\n",
    "            \n",
    "#             # Red Light Running\n",
    "#             print(\"   # Extracting Red Light Running\")\n",
    "#             df_red_running_id = traffic_feature_extract.extract_red_running(signal_id=signal_id, \n",
    "#                                                                             with_countbar=True)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error Processing Date {date}: {e}\")\n",
    "\n",
    "#     # Explicitly call garbage collector\n",
    "#     gc.collect()\n",
    "\n",
    "#     # Clear output after processing each Signal ID\n",
    "#     clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
