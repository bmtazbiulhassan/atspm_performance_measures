{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import yaml\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.feature_extraction import feature_extraction\n",
    "from src.utils import get_root_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get root directory of the project\n",
    "root_dir = get_root_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximize Column Display \n",
    "pd.set_option('display.max_colwidth', None)     # Display all content within each cell without truncation\n",
    "pd.set_option('display.max_columns', None)      # Display all columns\n",
    "pd.set_option('display.width', None)            # Display entire width of DataFrame is displayed\n",
    "\n",
    "pd.set_option('display.max_rows', None)         # Display all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Traffic Signal Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDOT D5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "signal_ids = [\n",
    "    \"1285\", \"1290\",\n",
    "    \"1300\", \"1315\", \"1325\", \"1330\", \n",
    "    \"1455\", \"1470\", \"1490\",\n",
    "    \"1500\", \"1555\",\n",
    "    \"1707\", \"1725\", \"1790\", \"1795\", \n",
    "    \"1960\",\n",
    "    \"2055\", \n",
    "    \"2485\", \n",
    "    \"2665\", \n",
    "    # \"D5I-3000\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Signal ID: 2665\n",
      "========================================\n",
      "  Processing Date: 2024-06-01\n",
      "   # Extracting Split Failure\n",
      "\n",
      "\n",
      "  Processing Date: 2024-06-02\n",
      "   # Extracting Split Failure\n",
      "\n",
      "\n",
      "  Processing Date: 2024-06-03\n",
      "  Processing Date: 2024-06-04\n",
      "  Processing Date: 2024-06-05\n",
      "  Processing Date: 2024-06-06\n",
      "  Processing Date: 2024-06-07\n",
      "  Processing Date: 2024-06-11\n",
      "  Processing Date: 2024-06-12\n",
      "  Processing Date: 2024-06-13\n",
      "  Processing Date: 2024-06-14\n",
      "  Processing Date: 2024-06-15\n",
      "  Processing Date: 2024-06-16\n",
      "  Processing Date: 2024-06-17\n",
      "  Processing Date: 2024-06-18\n",
      "  Processing Date: 2024-06-19\n",
      "  Processing Date: 2024-06-20\n",
      "  Processing Date: 2024-06-21\n",
      "  Processing Date: 2024-06-22\n",
      "  Processing Date: 2024-06-23\n",
      "  Processing Date: 2024-06-24\n",
      "  Processing Date: 2024-06-25\n",
      "  Processing Date: 2024-06-26\n",
      "  Processing Date: 2024-06-27\n",
      "  Processing Date: 2024-06-28\n",
      "  Processing Date: 2024-06-29\n",
      "  Processing Date: 2024-06-30\n",
      "  Processing Date: 2024-09-18\n",
      "  Processing Date: 2024-09-19\n",
      "  Processing Date: 2665\n",
      "Error Processing Date 2665: time data '2665' does not match format '%Y-%m-%d'\n"
     ]
    }
   ],
   "source": [
    "for signal_id in signal_ids:\n",
    "    print(f\"Processing Signal ID: {signal_id}\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # Define the filepaths\n",
    "    filepaths = f\"../data/interim/atspm/fdot_d5/event_data/{signal_id}/*.pkl\"\n",
    "    filepaths = [p for p in glob.glob(filepaths)][1:]  # Exclude first file, if needed\n",
    "\n",
    "    # Extract dates from filepaths\n",
    "    dates = [os.path.basename(filepath).split(\".\")[0] for filepath in filepaths]\n",
    "\n",
    "    for date in dates:\n",
    "        print(f\"  Processing Date: {date}\")\n",
    "\n",
    "        try:\n",
    "            # Parse the date string into a datetime object\n",
    "            date_object = datetime.strptime(date, '%Y-%m-%d')\n",
    "\n",
    "            # Extract day, month, and year\n",
    "            day = date_object.day\n",
    "            month = date_object.month\n",
    "            year = date_object.year\n",
    "\n",
    "            # if not ((month == 6) and (day in [1, 2])):\n",
    "            #     continue\n",
    "\n",
    "            if month != 6:\n",
    "                continue\n",
    "\n",
    "            # Extract Traffic Signal Profile\n",
    "            traffic_signal_profile = feature_extraction.TrafficSignalProfile(day=day, \n",
    "                                                                             month=month, \n",
    "                                                                             year=year)\n",
    "\n",
    "            df_vehicle_phase_profile_id = traffic_signal_profile.extract_vehicle_phase_profile(signal_id=signal_id)\n",
    "            df_vehicle_cycle_profile_id = traffic_signal_profile.extract_vehicle_cycle_profile(signal_id=signal_id)\n",
    "\n",
    "            df_pedestrian_phase_profile_id = traffic_signal_profile.extract_pedestrian_phase_profile(signal_id=signal_id)\n",
    "            df_pedestrian_cycle_profile_id = traffic_signal_profile.extract_pedestrian_cycle_profile(signal_id=signal_id)\n",
    "\n",
    "            # Extract signal features\n",
    "            signal_feature_extract = feature_extraction.SignalFeatureExtract(day=day, \n",
    "                                                                             month=month, \n",
    "                                                                             year=year)\n",
    "\n",
    "            print(\"   # Extracting SPaT\")\n",
    "            df_spat_id = signal_feature_extract.extract_spat(signal_id=signal_id)\n",
    "\n",
    "            # Extract traffic features\n",
    "            traffic_feature_extract = feature_extraction.TrafficFeatureExtract(day=day, \n",
    "                                                                               month=month,\n",
    "                                                                               year=year)\n",
    "            # Volume\n",
    "            print(\"   # Extracting Volume\")\n",
    "            df_volume_id = traffic_feature_extract.extract_volume(signal_id=signal_id, \n",
    "                                                                  with_countbar=False)\n",
    "            \n",
    "            # Occupancy\n",
    "            print(\"   # Extracting Occupancy\")\n",
    "            df_occupancy_id = traffic_feature_extract.extract_occupancy(signal_id=signal_id)\n",
    "\n",
    "            # Split Failure\n",
    "            print(\"   # Extracting Split Failure\")\n",
    "            df_split_failure_id = traffic_feature_extract.extract_split_failure(signal_id=signal_id)\n",
    "\n",
    "            # Headway\n",
    "            print(\"   # Extracting Headway\")\n",
    "            df_headway_id = traffic_feature_extract.extract_headway(signal_id=signal_id)\n",
    "\n",
    "            # Conflict\n",
    "            print(\"   # Extracting Conflict\")\n",
    "            df_conflict_id = traffic_feature_extract.extract_conflict(signal_id=signal_id)\n",
    "            \n",
    "            # Red Light Running\n",
    "            print(\"   # Extracting Red Light Running\")\n",
    "            df_red_running_id = traffic_feature_extract.extract_red_running(signal_id=signal_id, \n",
    "                                                                            with_countbar=False)\n",
    "\n",
    "            # Pedestrian Volume\n",
    "            print(\"   # Extracting Pedestrian Volume\")\n",
    "            df_pedestrian_volume_id = traffic_feature_extract.extract_pedestrian_volume(signal_id=signal_id)\n",
    "\n",
    "            # Pedestrian Delay\n",
    "            print(\"   # Extracting Pedestrian Delay\")\n",
    "            df_pedestrian_delay_id = traffic_feature_extract.extract_pedestrian_delay(signal_id=signal_id)\n",
    "\n",
    "            print(\"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error Processing Date {date}: {e}\")\n",
    "\n",
    "    # Explicitly call garbage collector\n",
    "    gc.collect()\n",
    "\n",
    "    # Clear output after processing each Signal ID\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signalID</th>\n",
       "      <th>cycleNo</th>\n",
       "      <th>date</th>\n",
       "      <th>cycleBegin</th>\n",
       "      <th>cycleEnd</th>\n",
       "      <th>cycleLength</th>\n",
       "      <th>greenSplitFailurePhase1</th>\n",
       "      <th>greenSplitFailurePhase4</th>\n",
       "      <th>greenSplitFailurePhase5</th>\n",
       "      <th>greenSplitFailurePhase8</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2665</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-06-02</td>\n",
       "      <td>2024-06-02 00:06:03.900</td>\n",
       "      <td>2024-06-02 00:18:49.300</td>\n",
       "      <td>765.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  signalID  cycleNo        date              cycleBegin  \\\n",
       "0     2665        4  2024-06-02 2024-06-02 00:06:03.900   \n",
       "\n",
       "                 cycleEnd  cycleLength  greenSplitFailurePhase1  \\\n",
       "0 2024-06-02 00:18:49.300        765.4                        0   \n",
       "\n",
       "   greenSplitFailurePhase4  greenSplitFailurePhase5  greenSplitFailurePhase8  \\\n",
       "0                        0                        0                        0   \n",
       "\n",
       "   hour  \n",
       "0     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split_failure_id.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Join Data**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define the directory paths\n",
    "dirpaths = \"../data/production/atspm/fdot_d5/feature_extraction/feature/*\"\n",
    "dirpaths = [dirpath for dirpath in glob.glob(dirpaths)]\n",
    "\n",
    "# Initialize dictionary to hold DataFrames\n",
    "dict_join = {f\"df_{os.path.basename(dirpath)}\": pd.DataFrame() for dirpath in dirpaths}\n",
    "\n",
    "# Iterate through each directory path\n",
    "for dirpath in tqdm.tqdm(dirpaths):\n",
    "    key = os.path.basename(dirpath)  # Extract the last part of the path for the key\n",
    "    event_types = [\"vehicle_signal\", \"vehicle_traffic\", \"pedestrian_traffic\"]\n",
    "\n",
    "    for event_type in event_types:\n",
    "        event_path = f\"{dirpath}/{event_type}\"\n",
    "\n",
    "        # Check if the event path exists to avoid errors\n",
    "        if not os.path.exists(event_path):\n",
    "            continue\n",
    "\n",
    "        features = os.listdir(event_path)\n",
    "\n",
    "        for feature in features:\n",
    "            feature_path = f\"{event_path}/{feature}\"\n",
    "\n",
    "            signal_ids = os.listdir(feature_path)\n",
    "\n",
    "            df = pd.DataFrame()\n",
    "            for signal_id in signal_ids:\n",
    "                signal_path = f\"{feature_path}/{signal_id}\"\n",
    "                filepaths = glob.glob(f\"{signal_path}/*\")\n",
    "\n",
    "                # Read and concatenate all files for the current signal ID\n",
    "                for filepath in filepaths:\n",
    "                    df = pd.concat([df, pd.read_pickle(filepath)], axis=0, ignore_index=True)\n",
    "\n",
    "            # Merge or concatenate with the corresponding DataFrame in dict_join\n",
    "            common_columns = list(set(df.columns).intersection(set(dict_join[f\"df_{key}\"].columns)))\n",
    "\n",
    "            if not common_columns:\n",
    "                # If no common columns, concatenate along axis=1\n",
    "                dict_join[f\"df_{key}\"] = pd.concat([dict_join[f\"df_{key}\"], df], axis=1)\n",
    "            else:\n",
    "                # If common columns exist, perform a left merge\n",
    "                dict_join[f\"df_{key}\"] = pd.merge(dict_join[f\"df_{key}\"], df, on=common_columns, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_join[\"df_cycle\"].to_csv(\"../data/production/atspm/fdot_d5/feature_extraction/feature/cycle/cycle.csv\", \n",
    "                             index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_join[\"df_hourly\"].to_csv(\"../data/production/atspm/fdot_d5/feature_extraction/feature/cycle/hourly.csv\", \n",
    "                              index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDOT D7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configurations\n",
    "# signal_ids = [\"1067\", \"1068\", \"1301\", \"1392\", \"1435\", \"1439\", \"1445\", \"1501\", \"1506\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for signal_id in signal_ids:\n",
    "#     print(f\"Processing Signal ID: {signal_id}\")\n",
    "#     print(\"=\" * 40)\n",
    "\n",
    "#     # Define the filepaths\n",
    "#     filepaths = f\"../data/interim/atspm/fdot_d7/event_data/{signal_id}/*.pkl\"\n",
    "#     filepaths = [p for p in glob.glob(filepaths)][1:]  # Exclude first file, if needed\n",
    "\n",
    "#     # Extract dates from filepaths\n",
    "#     dates = [os.path.basename(filepath).split(\".\")[0] for filepath in filepaths]\n",
    "\n",
    "#     for date in dates:\n",
    "#         print(f\"  Processing Date: {date}\")\n",
    "\n",
    "#         try:\n",
    "#             # Parse the date string into a datetime object\n",
    "#             date_object = datetime.strptime(date, '%Y-%m-%d')\n",
    "\n",
    "#             # Extract day, month, and year\n",
    "#             day = date_object.day\n",
    "#             month = date_object.month\n",
    "#             year = date_object.year\n",
    "\n",
    "#             # Extract Traffic Signal Profile\n",
    "#             traffic_signal_profile = feature_extraction.TrafficSignalProfile(day=day, \n",
    "#                                                                              month=month, \n",
    "#                                                                              year=year)\n",
    "#             df_vehicle_phase_profile_id = traffic_signal_profile.extract_vehicle_phase_profile(signal_id=signal_id)\n",
    "#             df_vehicle_cycle_profile_id = traffic_signal_profile.extract_vehicle_cycle_profile(signal_id=signal_id)\n",
    "\n",
    "#             # Extract signal features\n",
    "#             signal_feature_extract = feature_extraction.SignalFeatureExtract(day=day, \n",
    "#                                                                              month=month, \n",
    "#                                                                              year=year)\n",
    "\n",
    "#             print(\"   # Extracting SPaT\")\n",
    "#             df_spat_id = signal_feature_extract.extract_spat(signal_id=signal_id)\n",
    "\n",
    "#             # Extract traffic features\n",
    "#             traffic_feature_extract = feature_extraction.TrafficFeatureExtract(day=day, \n",
    "#                                                                                month=month,\n",
    "#                                                                                year=year)\n",
    "#             # Volume\n",
    "#             print(\"   # Extracting Volume\")\n",
    "#             df_volume_id = traffic_feature_extract.extract_volume(signal_id=signal_id, \n",
    "#                                                                   with_countbar=True)\n",
    "            \n",
    "#             # Occupancy\n",
    "#             print(\"   # Extracting Occupancy\")\n",
    "#             df_occupancy_id = traffic_feature_extract.extract_occupancy(signal_id=signal_id)\n",
    "\n",
    "#             # # Split Failure\n",
    "#             # print(\"   # Extracting Split Failure\")\n",
    "#             # df_split_failure_id = traffic_feature_extract.extract_split_failure(signal_id=signal_id)\n",
    "            \n",
    "#             # Red Light Running\n",
    "#             print(\"   # Extracting Red Light Running\")\n",
    "#             df_red_running_id = traffic_feature_extract.extract_red_running(signal_id=signal_id, \n",
    "#                                                                             with_countbar=True)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error Processing Date {date}: {e}\")\n",
    "\n",
    "#     # Explicitly call garbage collector\n",
    "#     gc.collect()\n",
    "\n",
    "#     # Clear output after processing each Signal ID\n",
    "#     clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
